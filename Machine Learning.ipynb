{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import plotly.express as px\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset/data\n",
    "\n",
    "https://www.kaggle.com/code/alexteboul/diabetes-health-indicators-dataset-notebook\n",
    "\n",
    "https://www.cdc.gov/brfss/annual_data/2015/pdf/codebook15_llcp.pdf\n",
    "\n",
    "* We want to... predict if someone is pre-diabetic or has diabetes from certain health metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Data\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df = pd.read_csv('./Data/CUSTOM_diabetes_012_health_indicators_BRFSS2015.csv')\n",
    "diabetes_binary_df = pd.read_csv('./Data/CUSTOM__BINARY_diabetes_012_health_indicators_BRFSS2015.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize what each column means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore & Summarize Data\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes_012\n",
       "0.0    208156\n",
       "2.0     34340\n",
       "1.0      4476\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df['Diabetes_012'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_012</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>Arthritis</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Race_white</th>\n",
       "      <th>Race_black</th>\n",
       "      <th>Race_AMI_AKN</th>\n",
       "      <th>Race_asian</th>\n",
       "      <th>Race_HI_PI</th>\n",
       "      <th>Race_other</th>\n",
       "      <th>Race_multi</th>\n",
       "      <th>Race_hispanic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  Arthritis  Depression  \\\n",
       "0                   0.0           0.0     0.0  ...        1.0         1.0   \n",
       "1                   0.0           1.0     0.0  ...        0.0         0.0   \n",
       "2                   0.0           0.0     1.0  ...        1.0         1.0   \n",
       "3                   0.0           1.0     1.0  ...        1.0         0.0   \n",
       "4                   0.0           1.0     1.0  ...        0.0         0.0   \n",
       "\n",
       "   Race_white  Race_black  Race_AMI_AKN  Race_asian  Race_HI_PI  Race_other  \\\n",
       "0           1           0             0           0           0           0   \n",
       "1           1           0             0           0           0           0   \n",
       "2           1           0             0           0           0           0   \n",
       "3           1           0             0           0           0           0   \n",
       "4           0           0             0           0           0           0   \n",
       "\n",
       "   Race_multi  Race_hispanic  \n",
       "0           0              0  \n",
       "1           0              0  \n",
       "2           0              0  \n",
       "3           0              0  \n",
       "4           1              0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_012</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>Arthritis</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Race_white</th>\n",
       "      <th>Race_black</th>\n",
       "      <th>Race_AMI_AKN</th>\n",
       "      <th>Race_asian</th>\n",
       "      <th>Race_HI_PI</th>\n",
       "      <th>Race_other</th>\n",
       "      <th>Race_multi</th>\n",
       "      <th>Race_hispanic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>246972.000000</td>\n",
       "      <td>246972.000000</td>\n",
       "      <td>246972.000000</td>\n",
       "      <td>246972.000000</td>\n",
       "      <td>246972.000000</td>\n",
       "      <td>246972.000000</td>\n",
       "      <td>246972.000000</td>\n",
       "      <td>246972.000000</td>\n",
       "      <td>246972.000000</td>\n",
       "      <td>246972.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>246972.000000</td>\n",
       "      <td>246972.000000</td>\n",
       "      <td>246972.000000</td>\n",
       "      <td>246972.000000</td>\n",
       "      <td>246972.000000</td>\n",
       "      <td>246972.000000</td>\n",
       "      <td>246972.000000</td>\n",
       "      <td>246972.000000</td>\n",
       "      <td>246972.000000</td>\n",
       "      <td>246972.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.296212</td>\n",
       "      <td>0.429239</td>\n",
       "      <td>0.424226</td>\n",
       "      <td>0.963672</td>\n",
       "      <td>28.379330</td>\n",
       "      <td>0.441908</td>\n",
       "      <td>0.040162</td>\n",
       "      <td>0.093492</td>\n",
       "      <td>0.758240</td>\n",
       "      <td>0.63504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.356478</td>\n",
       "      <td>0.199043</td>\n",
       "      <td>0.803119</td>\n",
       "      <td>0.071996</td>\n",
       "      <td>0.012876</td>\n",
       "      <td>0.020006</td>\n",
       "      <td>0.002964</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>0.017962</td>\n",
       "      <td>0.067457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.697539</td>\n",
       "      <td>0.494969</td>\n",
       "      <td>0.494226</td>\n",
       "      <td>0.187105</td>\n",
       "      <td>6.592675</td>\n",
       "      <td>0.496615</td>\n",
       "      <td>0.196340</td>\n",
       "      <td>0.291122</td>\n",
       "      <td>0.428151</td>\n",
       "      <td>0.48142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.478960</td>\n",
       "      <td>0.399281</td>\n",
       "      <td>0.397642</td>\n",
       "      <td>0.258482</td>\n",
       "      <td>0.112740</td>\n",
       "      <td>0.140022</td>\n",
       "      <td>0.054361</td>\n",
       "      <td>0.060056</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>0.250812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Diabetes_012         HighBP       HighChol      CholCheck  \\\n",
       "count  246972.000000  246972.000000  246972.000000  246972.000000   \n",
       "mean        0.296212       0.429239       0.424226       0.963672   \n",
       "std         0.697539       0.494969       0.494226       0.187105   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       1.000000   \n",
       "50%         0.000000       0.000000       0.000000       1.000000   \n",
       "75%         0.000000       1.000000       1.000000       1.000000   \n",
       "max         2.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                 BMI         Smoker         Stroke  HeartDiseaseorAttack  \\\n",
       "count  246972.000000  246972.000000  246972.000000         246972.000000   \n",
       "mean       28.379330       0.441908       0.040162              0.093492   \n",
       "std         6.592675       0.496615       0.196340              0.291122   \n",
       "min        12.000000       0.000000       0.000000              0.000000   \n",
       "25%        24.000000       0.000000       0.000000              0.000000   \n",
       "50%        27.000000       0.000000       0.000000              0.000000   \n",
       "75%        31.000000       1.000000       0.000000              0.000000   \n",
       "max        98.000000       1.000000       1.000000              1.000000   \n",
       "\n",
       "        PhysActivity        Fruits  ...      Arthritis     Depression  \\\n",
       "count  246972.000000  246972.00000  ...  246972.000000  246972.000000   \n",
       "mean        0.758240       0.63504  ...       0.356478       0.199043   \n",
       "std         0.428151       0.48142  ...       0.478960       0.399281   \n",
       "min         0.000000       0.00000  ...       0.000000       0.000000   \n",
       "25%         1.000000       0.00000  ...       0.000000       0.000000   \n",
       "50%         1.000000       1.00000  ...       0.000000       0.000000   \n",
       "75%         1.000000       1.00000  ...       1.000000       0.000000   \n",
       "max         1.000000       1.00000  ...       1.000000       1.000000   \n",
       "\n",
       "          Race_white     Race_black   Race_AMI_AKN     Race_asian  \\\n",
       "count  246972.000000  246972.000000  246972.000000  246972.000000   \n",
       "mean        0.803119       0.071996       0.012876       0.020006   \n",
       "std         0.397642       0.258482       0.112740       0.140022   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       0.000000       0.000000       0.000000   \n",
       "50%         1.000000       0.000000       0.000000       0.000000   \n",
       "75%         1.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "          Race_HI_PI     Race_other     Race_multi  Race_hispanic  \n",
       "count  246972.000000  246972.000000  246972.000000  246972.000000  \n",
       "mean        0.002964       0.003620       0.017962       0.067457  \n",
       "std         0.054361       0.060056       0.132812       0.250812  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       0.000000       0.000000  \n",
       "75%         0.000000       0.000000       0.000000       0.000000  \n",
       "max         1.000000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 34 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Clean Data / Adjust For Imbalance\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define and split the multiclass data \n",
    "X_multiclass = diabetes_df.drop('Diabetes_012', axis=1)\n",
    "y_multiclass = diabetes_df['Diabetes_012']\n",
    "X_train_multiclass, X_test_multiclass, y_train_multiclass, y_test_multiclass = train_test_split(X_multiclass, y_multiclass, random_state=0)\n",
    "#define and split the binary data\n",
    "X_binary = diabetes_binary_df.drop('Diabetes_012', axis=1)\n",
    "y_binary = diabetes_binary_df['Diabetes_012']\n",
    "X_train_binary, X_test_binary, y_train_binary, y_test_binary = train_test_split(X_binary, y_binary, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oversample the minority class\n",
    "ros_multiclass = RandomOverSampler(random_state=0)\n",
    "X_oversampled_multiclass, y_oversampled_multiclass = ros_multiclass.fit_resample(X_train_multiclass, y_train_multiclass)\n",
    "\n",
    "ros_binary = RandomOverSampler(random_state=0)\n",
    "X_oversampled_binary, y_oversampled_binary = ros_binary.fit_resample(X_train_binary, y_train_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#undersample the majority class\n",
    "rus_multiclass = RandomUnderSampler(random_state=0)\n",
    "X_undersampled_multiclass, y_undersampled_multiclass = rus_multiclass.fit_resample(X_train_multiclass, y_train_multiclass)\n",
    "\n",
    "rus_binary = RandomUnderSampler(random_state=0) \n",
    "X_undersampled_binary, y_undersampled_binary = rus_binary.fit_resample(X_train_binary, y_train_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312132"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_oversampled_binary.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Prepare for Modeling\n",
    "Split, Scale, etc.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale the Split Data to Prepare it for PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use StandardScaler to scale the data\n",
    "scaler_multiclass = StandardScaler().fit(X_oversampled_multiclass)\n",
    "X_oversampled_multiclass_scaled = scaler_multiclass.transform(X_oversampled_multiclass)\n",
    "X_undersampled_multiclass_scaled = scaler_multiclass.transform(X_undersampled_multiclass)\n",
    "X_test_multiclass_scaled = scaler_multiclass.transform(X_test_multiclass)\n",
    "\n",
    "#scale the binary data\n",
    "scaler_binary = StandardScaler().fit(X_oversampled_binary)\n",
    "X_oversampled_binary_scaled = scaler_binary.transform(X_oversampled_binary)\n",
    "X_undersampled_binary_scaled = scaler_binary.transform(X_undersampled_binary)\n",
    "X_test_binary_scaled = scaler_binary.transform(X_test_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform PCA maintaining 90% variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matt.dipinto\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but PCA was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#reduce dimensionality of the scaled data with pca\n",
    "pca = PCA(n_components=0.90, random_state=0)\n",
    "X_pca_oversampled_multiclass_scaled = pca.fit_transform(X_oversampled_multiclass_scaled)\n",
    "X_pca_undersampled_multiclass_scaled = pca.transform(X_undersampled_multiclass_scaled)\n",
    "X_pca_test_multiclass_scaled = pca.transform(X_test_multiclass)\n",
    "\n",
    "\n",
    "pca_binary = PCA(n_components=0.90, random_state=0)\n",
    "X_pca_oversampled_binary_scaled = pca_binary.fit_transform(X_oversampled_binary_scaled)\n",
    "X_pca_undersampled_binary_scaled = pca_binary.transform(X_undersampled_binary_scaled)\n",
    "X_pca_test_binary_scaled = pca_binary.transform(X_test_binary_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1174039 , 0.07192064, 0.05519846, 0.04516867, 0.03896104,\n",
       "       0.03732106, 0.03470428, 0.03346876, 0.03321441, 0.03187054,\n",
       "       0.03098369, 0.03066635, 0.03044568, 0.03027576, 0.02903621,\n",
       "       0.02776878, 0.02696034, 0.02470007, 0.02416049, 0.02363269,\n",
       "       0.02308903, 0.02285053, 0.02179342, 0.02111564, 0.02072047,\n",
       "       0.01996722])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>Arthritis</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Race_white</th>\n",
       "      <th>Race_black</th>\n",
       "      <th>Race_AMI_AKN</th>\n",
       "      <th>Race_asian</th>\n",
       "      <th>Race_HI_PI</th>\n",
       "      <th>Race_other</th>\n",
       "      <th>Race_multi</th>\n",
       "      <th>Race_hispanic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PC1</th>\n",
       "      <td>0.210146</td>\n",
       "      <td>0.166566</td>\n",
       "      <td>0.041250</td>\n",
       "      <td>0.166284</td>\n",
       "      <td>0.120284</td>\n",
       "      <td>0.146712</td>\n",
       "      <td>0.178724</td>\n",
       "      <td>-0.205994</td>\n",
       "      <td>-0.081892</td>\n",
       "      <td>-0.110781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255273</td>\n",
       "      <td>0.225950</td>\n",
       "      <td>-0.090270</td>\n",
       "      <td>0.070335</td>\n",
       "      <td>0.033075</td>\n",
       "      <td>-0.051068</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>0.009299</td>\n",
       "      <td>0.026285</td>\n",
       "      <td>0.062340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC2</th>\n",
       "      <td>-0.211402</td>\n",
       "      <td>-0.182129</td>\n",
       "      <td>-0.192997</td>\n",
       "      <td>0.009122</td>\n",
       "      <td>-0.079742</td>\n",
       "      <td>-0.070679</td>\n",
       "      <td>-0.148214</td>\n",
       "      <td>-0.021821</td>\n",
       "      <td>-0.081894</td>\n",
       "      <td>-0.077566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184462</td>\n",
       "      <td>0.058854</td>\n",
       "      <td>-0.367833</td>\n",
       "      <td>0.144064</td>\n",
       "      <td>0.096596</td>\n",
       "      <td>0.071656</td>\n",
       "      <td>0.043457</td>\n",
       "      <td>0.041929</td>\n",
       "      <td>0.070371</td>\n",
       "      <td>0.280969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC3</th>\n",
       "      <td>-0.155799</td>\n",
       "      <td>-0.036751</td>\n",
       "      <td>-0.247766</td>\n",
       "      <td>-0.011689</td>\n",
       "      <td>0.147121</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.022678</td>\n",
       "      <td>-0.014593</td>\n",
       "      <td>-0.071781</td>\n",
       "      <td>0.034873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029280</td>\n",
       "      <td>0.229071</td>\n",
       "      <td>0.532353</td>\n",
       "      <td>-0.378104</td>\n",
       "      <td>-0.080355</td>\n",
       "      <td>-0.146309</td>\n",
       "      <td>-0.043990</td>\n",
       "      <td>-0.025800</td>\n",
       "      <td>-0.088509</td>\n",
       "      <td>-0.254420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC4</th>\n",
       "      <td>0.173479</td>\n",
       "      <td>0.104213</td>\n",
       "      <td>-0.191119</td>\n",
       "      <td>-0.021727</td>\n",
       "      <td>0.226342</td>\n",
       "      <td>0.099213</td>\n",
       "      <td>0.200895</td>\n",
       "      <td>-0.122273</td>\n",
       "      <td>-0.297970</td>\n",
       "      <td>-0.293533</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087340</td>\n",
       "      <td>-0.340475</td>\n",
       "      <td>0.037389</td>\n",
       "      <td>-0.008802</td>\n",
       "      <td>0.038051</td>\n",
       "      <td>-0.061445</td>\n",
       "      <td>0.020698</td>\n",
       "      <td>-0.019513</td>\n",
       "      <td>-0.034979</td>\n",
       "      <td>-0.015459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC5</th>\n",
       "      <td>-0.021775</td>\n",
       "      <td>0.015456</td>\n",
       "      <td>-0.141983</td>\n",
       "      <td>-0.360195</td>\n",
       "      <td>0.047386</td>\n",
       "      <td>0.221066</td>\n",
       "      <td>0.250159</td>\n",
       "      <td>0.212281</td>\n",
       "      <td>0.493060</td>\n",
       "      <td>0.415265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089656</td>\n",
       "      <td>-0.120472</td>\n",
       "      <td>-0.042670</td>\n",
       "      <td>-0.159340</td>\n",
       "      <td>0.018042</td>\n",
       "      <td>0.050056</td>\n",
       "      <td>-0.012977</td>\n",
       "      <td>0.036570</td>\n",
       "      <td>0.038207</td>\n",
       "      <td>0.170673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC6</th>\n",
       "      <td>0.063902</td>\n",
       "      <td>0.139718</td>\n",
       "      <td>-0.012195</td>\n",
       "      <td>-0.060610</td>\n",
       "      <td>0.182790</td>\n",
       "      <td>0.222575</td>\n",
       "      <td>0.241418</td>\n",
       "      <td>0.138521</td>\n",
       "      <td>-0.038291</td>\n",
       "      <td>0.050299</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056187</td>\n",
       "      <td>0.085357</td>\n",
       "      <td>-0.253337</td>\n",
       "      <td>0.123834</td>\n",
       "      <td>0.101091</td>\n",
       "      <td>0.384263</td>\n",
       "      <td>0.061206</td>\n",
       "      <td>0.120755</td>\n",
       "      <td>0.315229</td>\n",
       "      <td>-0.197795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC7</th>\n",
       "      <td>0.097669</td>\n",
       "      <td>-0.029286</td>\n",
       "      <td>-0.310300</td>\n",
       "      <td>0.121918</td>\n",
       "      <td>-0.196432</td>\n",
       "      <td>0.060959</td>\n",
       "      <td>-0.074867</td>\n",
       "      <td>-0.028318</td>\n",
       "      <td>0.135869</td>\n",
       "      <td>-0.055165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170759</td>\n",
       "      <td>-0.099098</td>\n",
       "      <td>0.005936</td>\n",
       "      <td>0.493096</td>\n",
       "      <td>0.034829</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>-0.020955</td>\n",
       "      <td>-0.009959</td>\n",
       "      <td>-0.054140</td>\n",
       "      <td>-0.515921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC8</th>\n",
       "      <td>0.343710</td>\n",
       "      <td>0.323604</td>\n",
       "      <td>0.091413</td>\n",
       "      <td>0.401084</td>\n",
       "      <td>-0.048152</td>\n",
       "      <td>-0.143636</td>\n",
       "      <td>0.013077</td>\n",
       "      <td>0.169037</td>\n",
       "      <td>0.137325</td>\n",
       "      <td>0.271561</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021816</td>\n",
       "      <td>0.017617</td>\n",
       "      <td>0.030322</td>\n",
       "      <td>0.135998</td>\n",
       "      <td>-0.285679</td>\n",
       "      <td>-0.214162</td>\n",
       "      <td>0.083342</td>\n",
       "      <td>-0.039309</td>\n",
       "      <td>-0.116646</td>\n",
       "      <td>0.116774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC9</th>\n",
       "      <td>0.016292</td>\n",
       "      <td>-0.030659</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>-0.066352</td>\n",
       "      <td>0.435345</td>\n",
       "      <td>-0.110775</td>\n",
       "      <td>-0.148381</td>\n",
       "      <td>0.125767</td>\n",
       "      <td>0.054820</td>\n",
       "      <td>0.094759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078409</td>\n",
       "      <td>0.078709</td>\n",
       "      <td>-0.059580</td>\n",
       "      <td>0.259348</td>\n",
       "      <td>0.202096</td>\n",
       "      <td>-0.367582</td>\n",
       "      <td>-0.023442</td>\n",
       "      <td>-0.027877</td>\n",
       "      <td>0.221795</td>\n",
       "      <td>-0.177311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC10</th>\n",
       "      <td>0.046353</td>\n",
       "      <td>-0.144800</td>\n",
       "      <td>-0.118290</td>\n",
       "      <td>0.420689</td>\n",
       "      <td>-0.085367</td>\n",
       "      <td>-0.158992</td>\n",
       "      <td>0.006542</td>\n",
       "      <td>-0.179382</td>\n",
       "      <td>0.124071</td>\n",
       "      <td>0.237244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056794</td>\n",
       "      <td>-0.124655</td>\n",
       "      <td>-0.061691</td>\n",
       "      <td>-0.229351</td>\n",
       "      <td>0.339859</td>\n",
       "      <td>-0.269012</td>\n",
       "      <td>-0.073404</td>\n",
       "      <td>0.165544</td>\n",
       "      <td>0.397240</td>\n",
       "      <td>0.089850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC11</th>\n",
       "      <td>0.088505</td>\n",
       "      <td>0.147788</td>\n",
       "      <td>0.107066</td>\n",
       "      <td>0.078161</td>\n",
       "      <td>0.027741</td>\n",
       "      <td>-0.036228</td>\n",
       "      <td>-0.006684</td>\n",
       "      <td>0.134472</td>\n",
       "      <td>0.029283</td>\n",
       "      <td>0.037945</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>0.054076</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>-0.110861</td>\n",
       "      <td>0.768278</td>\n",
       "      <td>0.121330</td>\n",
       "      <td>0.129042</td>\n",
       "      <td>-0.189482</td>\n",
       "      <td>-0.483917</td>\n",
       "      <td>-0.052354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC12</th>\n",
       "      <td>-0.054306</td>\n",
       "      <td>-0.116742</td>\n",
       "      <td>0.055548</td>\n",
       "      <td>-0.023529</td>\n",
       "      <td>0.109982</td>\n",
       "      <td>-0.009711</td>\n",
       "      <td>0.038928</td>\n",
       "      <td>-0.022983</td>\n",
       "      <td>0.044111</td>\n",
       "      <td>0.039820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062133</td>\n",
       "      <td>-0.021838</td>\n",
       "      <td>-0.001237</td>\n",
       "      <td>0.148674</td>\n",
       "      <td>0.033704</td>\n",
       "      <td>-0.100207</td>\n",
       "      <td>-0.243070</td>\n",
       "      <td>0.815008</td>\n",
       "      <td>-0.418311</td>\n",
       "      <td>-0.030684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC13</th>\n",
       "      <td>-0.060210</td>\n",
       "      <td>-0.016904</td>\n",
       "      <td>-0.025788</td>\n",
       "      <td>-0.037310</td>\n",
       "      <td>-0.021309</td>\n",
       "      <td>-0.016928</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>-0.000225</td>\n",
       "      <td>-0.012057</td>\n",
       "      <td>-0.020257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017959</td>\n",
       "      <td>-0.021460</td>\n",
       "      <td>-0.004844</td>\n",
       "      <td>-0.083710</td>\n",
       "      <td>-0.037981</td>\n",
       "      <td>-0.119812</td>\n",
       "      <td>0.928010</td>\n",
       "      <td>0.294291</td>\n",
       "      <td>0.026871</td>\n",
       "      <td>-0.102708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC14</th>\n",
       "      <td>0.172795</td>\n",
       "      <td>0.240928</td>\n",
       "      <td>-0.198527</td>\n",
       "      <td>-0.007324</td>\n",
       "      <td>0.010174</td>\n",
       "      <td>-0.432675</td>\n",
       "      <td>-0.253368</td>\n",
       "      <td>-0.211501</td>\n",
       "      <td>0.008044</td>\n",
       "      <td>0.040925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202127</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.073646</td>\n",
       "      <td>-0.196116</td>\n",
       "      <td>-0.089461</td>\n",
       "      <td>0.493116</td>\n",
       "      <td>-0.000606</td>\n",
       "      <td>0.183139</td>\n",
       "      <td>-0.067149</td>\n",
       "      <td>0.085450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC15</th>\n",
       "      <td>0.091280</td>\n",
       "      <td>0.302609</td>\n",
       "      <td>0.133829</td>\n",
       "      <td>-0.072088</td>\n",
       "      <td>-0.076641</td>\n",
       "      <td>-0.037232</td>\n",
       "      <td>-0.084263</td>\n",
       "      <td>0.183587</td>\n",
       "      <td>-0.143863</td>\n",
       "      <td>-0.185321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029397</td>\n",
       "      <td>0.134499</td>\n",
       "      <td>0.055142</td>\n",
       "      <td>-0.247599</td>\n",
       "      <td>0.171854</td>\n",
       "      <td>-0.003186</td>\n",
       "      <td>-0.160906</td>\n",
       "      <td>0.307920</td>\n",
       "      <td>0.417543</td>\n",
       "      <td>-0.161599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC16</th>\n",
       "      <td>0.148220</td>\n",
       "      <td>0.301474</td>\n",
       "      <td>-0.264174</td>\n",
       "      <td>-0.038188</td>\n",
       "      <td>-0.362005</td>\n",
       "      <td>0.382378</td>\n",
       "      <td>0.127097</td>\n",
       "      <td>-0.039731</td>\n",
       "      <td>-0.095925</td>\n",
       "      <td>-0.102236</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092071</td>\n",
       "      <td>0.175355</td>\n",
       "      <td>-0.055926</td>\n",
       "      <td>-0.021588</td>\n",
       "      <td>0.042283</td>\n",
       "      <td>-0.280949</td>\n",
       "      <td>-0.025576</td>\n",
       "      <td>0.108665</td>\n",
       "      <td>-0.081088</td>\n",
       "      <td>0.265231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC17</th>\n",
       "      <td>0.006763</td>\n",
       "      <td>-0.214723</td>\n",
       "      <td>0.349437</td>\n",
       "      <td>0.097085</td>\n",
       "      <td>-0.265960</td>\n",
       "      <td>0.311949</td>\n",
       "      <td>0.043984</td>\n",
       "      <td>-0.315519</td>\n",
       "      <td>-0.013662</td>\n",
       "      <td>0.017259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020913</td>\n",
       "      <td>-0.227000</td>\n",
       "      <td>0.086266</td>\n",
       "      <td>-0.130371</td>\n",
       "      <td>0.093037</td>\n",
       "      <td>0.099421</td>\n",
       "      <td>-0.013089</td>\n",
       "      <td>0.044025</td>\n",
       "      <td>0.064428</td>\n",
       "      <td>-0.138014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC18</th>\n",
       "      <td>0.064311</td>\n",
       "      <td>-0.060994</td>\n",
       "      <td>-0.122213</td>\n",
       "      <td>0.422615</td>\n",
       "      <td>0.297222</td>\n",
       "      <td>0.430618</td>\n",
       "      <td>-0.123880</td>\n",
       "      <td>-0.002560</td>\n",
       "      <td>0.055574</td>\n",
       "      <td>0.170638</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154348</td>\n",
       "      <td>0.144206</td>\n",
       "      <td>0.054601</td>\n",
       "      <td>-0.104523</td>\n",
       "      <td>-0.129215</td>\n",
       "      <td>0.323683</td>\n",
       "      <td>0.016994</td>\n",
       "      <td>0.058809</td>\n",
       "      <td>-0.021799</td>\n",
       "      <td>-0.096616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC19</th>\n",
       "      <td>0.084472</td>\n",
       "      <td>-0.316955</td>\n",
       "      <td>-0.184967</td>\n",
       "      <td>0.209201</td>\n",
       "      <td>-0.221987</td>\n",
       "      <td>0.032415</td>\n",
       "      <td>0.003395</td>\n",
       "      <td>0.666932</td>\n",
       "      <td>-0.101877</td>\n",
       "      <td>-0.205953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294374</td>\n",
       "      <td>-0.067534</td>\n",
       "      <td>0.020042</td>\n",
       "      <td>-0.124636</td>\n",
       "      <td>-0.007789</td>\n",
       "      <td>0.097289</td>\n",
       "      <td>-0.029373</td>\n",
       "      <td>0.061531</td>\n",
       "      <td>-0.019645</td>\n",
       "      <td>0.051611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC20</th>\n",
       "      <td>0.088981</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.267709</td>\n",
       "      <td>-0.017886</td>\n",
       "      <td>-0.277905</td>\n",
       "      <td>-0.117027</td>\n",
       "      <td>0.021014</td>\n",
       "      <td>0.143809</td>\n",
       "      <td>0.291099</td>\n",
       "      <td>-0.207879</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136173</td>\n",
       "      <td>0.125570</td>\n",
       "      <td>0.081098</td>\n",
       "      <td>0.031907</td>\n",
       "      <td>-0.098271</td>\n",
       "      <td>0.052841</td>\n",
       "      <td>0.015258</td>\n",
       "      <td>0.029074</td>\n",
       "      <td>0.063107</td>\n",
       "      <td>-0.183740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC21</th>\n",
       "      <td>0.206977</td>\n",
       "      <td>0.051065</td>\n",
       "      <td>-0.238014</td>\n",
       "      <td>-0.042562</td>\n",
       "      <td>-0.119637</td>\n",
       "      <td>-0.046368</td>\n",
       "      <td>-0.129933</td>\n",
       "      <td>-0.079224</td>\n",
       "      <td>0.385532</td>\n",
       "      <td>-0.162890</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.507808</td>\n",
       "      <td>-0.152212</td>\n",
       "      <td>0.080581</td>\n",
       "      <td>-0.057267</td>\n",
       "      <td>0.096639</td>\n",
       "      <td>0.010546</td>\n",
       "      <td>-0.015545</td>\n",
       "      <td>-0.014931</td>\n",
       "      <td>0.065978</td>\n",
       "      <td>-0.145258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC22</th>\n",
       "      <td>0.018818</td>\n",
       "      <td>-0.204920</td>\n",
       "      <td>-0.183621</td>\n",
       "      <td>0.079977</td>\n",
       "      <td>-0.105098</td>\n",
       "      <td>-0.381708</td>\n",
       "      <td>0.713341</td>\n",
       "      <td>-0.090981</td>\n",
       "      <td>-0.107352</td>\n",
       "      <td>0.111552</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157803</td>\n",
       "      <td>0.181573</td>\n",
       "      <td>0.009431</td>\n",
       "      <td>0.034537</td>\n",
       "      <td>0.017620</td>\n",
       "      <td>0.106913</td>\n",
       "      <td>-0.012267</td>\n",
       "      <td>-0.027683</td>\n",
       "      <td>0.007383</td>\n",
       "      <td>-0.112221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC23</th>\n",
       "      <td>-0.005781</td>\n",
       "      <td>-0.180366</td>\n",
       "      <td>-0.250018</td>\n",
       "      <td>-0.015520</td>\n",
       "      <td>0.050745</td>\n",
       "      <td>0.076896</td>\n",
       "      <td>-0.073046</td>\n",
       "      <td>-0.182567</td>\n",
       "      <td>0.316827</td>\n",
       "      <td>-0.319649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244594</td>\n",
       "      <td>0.253489</td>\n",
       "      <td>-0.065360</td>\n",
       "      <td>-0.032794</td>\n",
       "      <td>0.074809</td>\n",
       "      <td>-0.038279</td>\n",
       "      <td>0.017989</td>\n",
       "      <td>-0.040968</td>\n",
       "      <td>-0.016807</td>\n",
       "      <td>0.134985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC24</th>\n",
       "      <td>-0.293698</td>\n",
       "      <td>0.195670</td>\n",
       "      <td>0.204998</td>\n",
       "      <td>0.248958</td>\n",
       "      <td>0.225488</td>\n",
       "      <td>-0.065292</td>\n",
       "      <td>0.293703</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.422428</td>\n",
       "      <td>-0.471102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089500</td>\n",
       "      <td>-0.058741</td>\n",
       "      <td>-0.013817</td>\n",
       "      <td>-0.044258</td>\n",
       "      <td>-0.053418</td>\n",
       "      <td>0.016837</td>\n",
       "      <td>-0.008457</td>\n",
       "      <td>0.022355</td>\n",
       "      <td>-0.016927</td>\n",
       "      <td>0.089417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC25</th>\n",
       "      <td>-0.356388</td>\n",
       "      <td>0.375978</td>\n",
       "      <td>-0.230580</td>\n",
       "      <td>0.019377</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>-0.057113</td>\n",
       "      <td>0.056884</td>\n",
       "      <td>0.188740</td>\n",
       "      <td>-0.094584</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.114013</td>\n",
       "      <td>-0.243973</td>\n",
       "      <td>0.028261</td>\n",
       "      <td>0.021587</td>\n",
       "      <td>0.019649</td>\n",
       "      <td>-0.029994</td>\n",
       "      <td>-0.056937</td>\n",
       "      <td>0.011316</td>\n",
       "      <td>0.013483</td>\n",
       "      <td>-0.056773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC26</th>\n",
       "      <td>0.122006</td>\n",
       "      <td>-0.065081</td>\n",
       "      <td>-0.259864</td>\n",
       "      <td>0.021862</td>\n",
       "      <td>0.200670</td>\n",
       "      <td>-0.006610</td>\n",
       "      <td>-0.048569</td>\n",
       "      <td>-0.008625</td>\n",
       "      <td>0.060618</td>\n",
       "      <td>-0.153143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108024</td>\n",
       "      <td>-0.136987</td>\n",
       "      <td>0.027594</td>\n",
       "      <td>-0.083865</td>\n",
       "      <td>-0.047188</td>\n",
       "      <td>-0.027687</td>\n",
       "      <td>0.009296</td>\n",
       "      <td>-0.016862</td>\n",
       "      <td>0.019209</td>\n",
       "      <td>0.073914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        HighBP  HighChol  CholCheck       BMI    Smoker    Stroke  \\\n",
       "PC1   0.210146  0.166566   0.041250  0.166284  0.120284  0.146712   \n",
       "PC2  -0.211402 -0.182129  -0.192997  0.009122 -0.079742 -0.070679   \n",
       "PC3  -0.155799 -0.036751  -0.247766 -0.011689  0.147121  0.002948   \n",
       "PC4   0.173479  0.104213  -0.191119 -0.021727  0.226342  0.099213   \n",
       "PC5  -0.021775  0.015456  -0.141983 -0.360195  0.047386  0.221066   \n",
       "PC6   0.063902  0.139718  -0.012195 -0.060610  0.182790  0.222575   \n",
       "PC7   0.097669 -0.029286  -0.310300  0.121918 -0.196432  0.060959   \n",
       "PC8   0.343710  0.323604   0.091413  0.401084 -0.048152 -0.143636   \n",
       "PC9   0.016292 -0.030659   0.005208 -0.066352  0.435345 -0.110775   \n",
       "PC10  0.046353 -0.144800  -0.118290  0.420689 -0.085367 -0.158992   \n",
       "PC11  0.088505  0.147788   0.107066  0.078161  0.027741 -0.036228   \n",
       "PC12 -0.054306 -0.116742   0.055548 -0.023529  0.109982 -0.009711   \n",
       "PC13 -0.060210 -0.016904  -0.025788 -0.037310 -0.021309 -0.016928   \n",
       "PC14  0.172795  0.240928  -0.198527 -0.007324  0.010174 -0.432675   \n",
       "PC15  0.091280  0.302609   0.133829 -0.072088 -0.076641 -0.037232   \n",
       "PC16  0.148220  0.301474  -0.264174 -0.038188 -0.362005  0.382378   \n",
       "PC17  0.006763 -0.214723   0.349437  0.097085 -0.265960  0.311949   \n",
       "PC18  0.064311 -0.060994  -0.122213  0.422615  0.297222  0.430618   \n",
       "PC19  0.084472 -0.316955  -0.184967  0.209201 -0.221987  0.032415   \n",
       "PC20  0.088981  0.001106   0.267709 -0.017886 -0.277905 -0.117027   \n",
       "PC21  0.206977  0.051065  -0.238014 -0.042562 -0.119637 -0.046368   \n",
       "PC22  0.018818 -0.204920  -0.183621  0.079977 -0.105098 -0.381708   \n",
       "PC23 -0.005781 -0.180366  -0.250018 -0.015520  0.050745  0.076896   \n",
       "PC24 -0.293698  0.195670   0.204998  0.248958  0.225488 -0.065292   \n",
       "PC25 -0.356388  0.375978  -0.230580  0.019377  0.005155 -0.057113   \n",
       "PC26  0.122006 -0.065081  -0.259864  0.021862  0.200670 -0.006610   \n",
       "\n",
       "      HeartDiseaseorAttack  PhysActivity    Fruits   Veggies  ...  Arthritis  \\\n",
       "PC1               0.178724     -0.205994 -0.081892 -0.110781  ...   0.255273   \n",
       "PC2              -0.148214     -0.021821 -0.081894 -0.077566  ...  -0.184462   \n",
       "PC3               0.022678     -0.014593 -0.071781  0.034873  ...   0.029280   \n",
       "PC4               0.200895     -0.122273 -0.297970 -0.293533  ...  -0.087340   \n",
       "PC5               0.250159      0.212281  0.493060  0.415265  ...   0.089656   \n",
       "PC6               0.241418      0.138521 -0.038291  0.050299  ...  -0.056187   \n",
       "PC7              -0.074867     -0.028318  0.135869 -0.055165  ...   0.170759   \n",
       "PC8               0.013077      0.169037  0.137325  0.271561  ...  -0.021816   \n",
       "PC9              -0.148381      0.125767  0.054820  0.094759  ...   0.078409   \n",
       "PC10              0.006542     -0.179382  0.124071  0.237244  ...   0.056794   \n",
       "PC11             -0.006684      0.134472  0.029283  0.037945  ...  -0.010464   \n",
       "PC12              0.038928     -0.022983  0.044111  0.039820  ...  -0.062133   \n",
       "PC13              0.002544     -0.000225 -0.012057 -0.020257  ...   0.017959   \n",
       "PC14             -0.253368     -0.211501  0.008044  0.040925  ...   0.202127   \n",
       "PC15             -0.084263      0.183587 -0.143863 -0.185321  ...   0.029397   \n",
       "PC16              0.127097     -0.039731 -0.095925 -0.102236  ...  -0.092071   \n",
       "PC17              0.043984     -0.315519 -0.013662  0.017259  ...  -0.020913   \n",
       "PC18             -0.123880     -0.002560  0.055574  0.170638  ...  -0.154348   \n",
       "PC19              0.003395      0.666932 -0.101877 -0.205953  ...   0.294374   \n",
       "PC20              0.021014      0.143809  0.291099 -0.207879  ...  -0.136173   \n",
       "PC21             -0.129933     -0.079224  0.385532 -0.162890  ...  -0.507808   \n",
       "PC22              0.713341     -0.090981 -0.107352  0.111552  ...  -0.157803   \n",
       "PC23             -0.073046     -0.182567  0.316827 -0.319649  ...   0.244594   \n",
       "PC24              0.293703      0.002145  0.422428 -0.471102  ...   0.089500   \n",
       "PC25              0.056884      0.188740 -0.094584  0.009781  ...  -0.114013   \n",
       "PC26             -0.048569     -0.008625  0.060618 -0.153143  ...  -0.108024   \n",
       "\n",
       "      Depression  Race_white  Race_black  Race_AMI_AKN  Race_asian  \\\n",
       "PC1     0.225950   -0.090270    0.070335      0.033075   -0.051068   \n",
       "PC2     0.058854   -0.367833    0.144064      0.096596    0.071656   \n",
       "PC3     0.229071    0.532353   -0.378104     -0.080355   -0.146309   \n",
       "PC4    -0.340475    0.037389   -0.008802      0.038051   -0.061445   \n",
       "PC5    -0.120472   -0.042670   -0.159340      0.018042    0.050056   \n",
       "PC6     0.085357   -0.253337    0.123834      0.101091    0.384263   \n",
       "PC7    -0.099098    0.005936    0.493096      0.034829    0.022100   \n",
       "PC8     0.017617    0.030322    0.135998     -0.285679   -0.214162   \n",
       "PC9     0.078709   -0.059580    0.259348      0.202096   -0.367582   \n",
       "PC10   -0.124655   -0.061691   -0.229351      0.339859   -0.269012   \n",
       "PC11    0.054076    0.000464   -0.110861      0.768278    0.121330   \n",
       "PC12   -0.021838   -0.001237    0.148674      0.033704   -0.100207   \n",
       "PC13   -0.021460   -0.004844   -0.083710     -0.037981   -0.119812   \n",
       "PC14   -0.026328   -0.073646   -0.196116     -0.089461    0.493116   \n",
       "PC15    0.134499    0.055142   -0.247599      0.171854   -0.003186   \n",
       "PC16    0.175355   -0.055926   -0.021588      0.042283   -0.280949   \n",
       "PC17   -0.227000    0.086266   -0.130371      0.093037    0.099421   \n",
       "PC18    0.144206    0.054601   -0.104523     -0.129215    0.323683   \n",
       "PC19   -0.067534    0.020042   -0.124636     -0.007789    0.097289   \n",
       "PC20    0.125570    0.081098    0.031907     -0.098271    0.052841   \n",
       "PC21   -0.152212    0.080581   -0.057267      0.096639    0.010546   \n",
       "PC22    0.181573    0.009431    0.034537      0.017620    0.106913   \n",
       "PC23    0.253489   -0.065360   -0.032794      0.074809   -0.038279   \n",
       "PC24   -0.058741   -0.013817   -0.044258     -0.053418    0.016837   \n",
       "PC25   -0.243973    0.028261    0.021587      0.019649   -0.029994   \n",
       "PC26   -0.136987    0.027594   -0.083865     -0.047188   -0.027687   \n",
       "\n",
       "      Race_HI_PI  Race_other  Race_multi  Race_hispanic  \n",
       "PC1     0.004783    0.009299    0.026285       0.062340  \n",
       "PC2     0.043457    0.041929    0.070371       0.280969  \n",
       "PC3    -0.043990   -0.025800   -0.088509      -0.254420  \n",
       "PC4     0.020698   -0.019513   -0.034979      -0.015459  \n",
       "PC5    -0.012977    0.036570    0.038207       0.170673  \n",
       "PC6     0.061206    0.120755    0.315229      -0.197795  \n",
       "PC7    -0.020955   -0.009959   -0.054140      -0.515921  \n",
       "PC8     0.083342   -0.039309   -0.116646       0.116774  \n",
       "PC9    -0.023442   -0.027877    0.221795      -0.177311  \n",
       "PC10   -0.073404    0.165544    0.397240       0.089850  \n",
       "PC11    0.129042   -0.189482   -0.483917      -0.052354  \n",
       "PC12   -0.243070    0.815008   -0.418311      -0.030684  \n",
       "PC13    0.928010    0.294291    0.026871      -0.102708  \n",
       "PC14   -0.000606    0.183139   -0.067149       0.085450  \n",
       "PC15   -0.160906    0.307920    0.417543      -0.161599  \n",
       "PC16   -0.025576    0.108665   -0.081088       0.265231  \n",
       "PC17   -0.013089    0.044025    0.064428      -0.138014  \n",
       "PC18    0.016994    0.058809   -0.021799      -0.096616  \n",
       "PC19   -0.029373    0.061531   -0.019645       0.051611  \n",
       "PC20    0.015258    0.029074    0.063107      -0.183740  \n",
       "PC21   -0.015545   -0.014931    0.065978      -0.145258  \n",
       "PC22   -0.012267   -0.027683    0.007383      -0.112221  \n",
       "PC23    0.017989   -0.040968   -0.016807       0.134985  \n",
       "PC24   -0.008457    0.022355   -0.016927       0.089417  \n",
       "PC25   -0.056937    0.011316    0.013483      -0.056773  \n",
       "PC26    0.009296   -0.016862    0.019209       0.073914  \n",
       "\n",
       "[26 rows x 33 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components = pca.components_\n",
    "\n",
    "feature_names = list(X_multiclass.columns)\n",
    "components_df = pd.DataFrame(components, columns=feature_names, index=[f'PC{i+1}' for i in range(components.shape[0])])\n",
    "\n",
    "components_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matt.dipinto\\AppData\\Local\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\matt.dipinto\\AppData\\Local\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\matt.dipinto\\AppData\\Local\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "component = 'PC1'\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=components_df.loc[component], y=components_df.columns)\n",
    "plt.title(f'Feature Contributions to {component}')\n",
    "plt.xlabel('Contribution')\n",
    "plt.ylabel('Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Test Various models with default params\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import unsupervised models\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#Import supervised models\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Initial Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression on oversampled and undersampled multiclass data\n",
    "lr_ros = LogisticRegression(max_iter=10000).fit(X_oversampled_multiclass, y_oversampled_multiclass)\n",
    "lr_rus = LogisticRegression(max_iter=10000).fit(X_undersampled_multiclass, y_undersampled_multiclass)\n",
    "#logistic regression on oversampled and undersampled binary data\n",
    "lr_ros_binary = LogisticRegression(max_iter=10000).fit(X_oversampled_binary, y_oversampled_binary)\n",
    "lr_rus_binary = LogisticRegression(max_iter=10000).fit(X_undersampled_binary, y_undersampled_binary) \n",
    "#logistic regression on binary data after pca\n",
    "lr_ros_pca_binary = LogisticRegression(max_iter=10000).fit(X_pca_oversampled_binary_scaled, y_oversampled_binary)\n",
    "lr_rus_pca_binary = LogisticRegression(max_iter=10000).fit(X_pca_undersampled_binary_scaled, y_undersampled_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Oversampling logistic regression model produced the following:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.66      0.63    156066\n",
      "         1.0       0.45      0.35      0.39    156066\n",
      "         2.0       0.51      0.59      0.55    156066\n",
      "\n",
      "    accuracy                           0.53    468198\n",
      "   macro avg       0.52      0.53      0.52    468198\n",
      "weighted avg       0.52      0.53      0.52    468198\n",
      "\n",
      "Random Oversampling on the test data produced the following:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.66      0.78     52090\n",
      "         1.0       0.03      0.34      0.06      1091\n",
      "         2.0       0.35      0.58      0.44      8562\n",
      "\n",
      "    accuracy                           0.65     61743\n",
      "   macro avg       0.45      0.53      0.43     61743\n",
      "weighted avg       0.85      0.65      0.72     61743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#multiclass train and test accuracy (oversampled)\n",
    "print(\"Random Oversampling logistic regression model produced the following:\\n\" + classification_report(y_oversampled_multiclass, lr_ros.predict(X_oversampled_multiclass)))\n",
    "print(\"Random Oversampling on the test data produced the following:\\n\" + classification_report(y_test_multiclass, lr_ros.predict(X_test_multiclass)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Undersampling logistic regression model produced the following:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.67      0.64      3385\n",
      "         1.0       0.45      0.34      0.39      3385\n",
      "         2.0       0.52      0.60      0.56      3385\n",
      "\n",
      "    accuracy                           0.54     10155\n",
      "   macro avg       0.53      0.54      0.53     10155\n",
      "weighted avg       0.53      0.54      0.53     10155\n",
      "\n",
      "Random undersampling on the test data produced the following:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.66      0.78     52090\n",
      "         1.0       0.03      0.33      0.06      1091\n",
      "         2.0       0.35      0.58      0.44      8562\n",
      "\n",
      "    accuracy                           0.65     61743\n",
      "   macro avg       0.45      0.53      0.43     61743\n",
      "weighted avg       0.85      0.65      0.72     61743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#multiclass train and test accuracy (undersampled)\n",
    "print(\"Random Undersampling logistic regression model produced the following:\\n\" + classification_report(y_undersampled_multiclass, lr_rus.predict(X_undersampled_multiclass)))\n",
    "print(\"Random undersampling on the test data produced the following:\\n\" + classification_report(y_test_multiclass, lr_rus.predict(X_test_multiclass)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    454\n",
       "1.0    369\n",
       "0.0    268\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_undersampled = pd.concat([X_test_multiclass,y_test_multiclass], axis=1)\n",
    "merged_undersampled = merged_undersampled.loc[merged_undersampled['Diabetes_012'] == 1]\n",
    "predicitions = lr_ros.predict(merged_undersampled.drop('Diabetes_012', axis=1))\n",
    "pd.Series(predicitions).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Oversampling logistic regression model produced the following:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.73      0.74    156066\n",
      "         1.0       0.74      0.77      0.75    156066\n",
      "\n",
      "    accuracy                           0.75    312132\n",
      "   macro avg       0.75      0.75      0.75    312132\n",
      "weighted avg       0.75      0.75      0.75    312132\n",
      "\n",
      "Random Oversampling on the test data produced the following:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.73      0.82     52090\n",
      "         1.0       0.34      0.77      0.47      9653\n",
      "\n",
      "    accuracy                           0.73     61743\n",
      "   macro avg       0.64      0.75      0.65     61743\n",
      "weighted avg       0.85      0.73      0.77     61743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#binary train and test accuracy (oversampled)\n",
    "print(\"Random Oversampling logistic regression model produced the following:\\n\" + classification_report(y_oversampled_binary, lr_ros_binary.predict(X_oversampled_binary)))\n",
    "print(\"Random Oversampling on the test data produced the following:\\n\" + classification_report(y_test_binary, lr_ros_binary.predict(X_test_binary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Undersampling logistic regression model produced the following:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.73      0.74     29163\n",
      "         1.0       0.74      0.77      0.75     29163\n",
      "\n",
      "    accuracy                           0.75     58326\n",
      "   macro avg       0.75      0.75      0.75     58326\n",
      "weighted avg       0.75      0.75      0.75     58326\n",
      "\n",
      "Random undersampling on the test data produced the following:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.73      0.82     52090\n",
      "         1.0       0.34      0.77      0.47      9653\n",
      "\n",
      "    accuracy                           0.73     61743\n",
      "   macro avg       0.64      0.75      0.65     61743\n",
      "weighted avg       0.85      0.73      0.77     61743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#binary train and test accuracy (undersampled)\n",
    "print(\"Random Undersampling logistic regression model produced the following:\\n\" + classification_report(y_undersampled_binary, lr_rus_binary.predict(X_undersampled_binary)))\n",
    "print(\"Random undersampling on the test data produced the following:\\n\" + classification_report(y_test_binary, lr_rus_binary.predict(X_test_binary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Oversampling logistic regression model produced the following:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.72      0.73    156066\n",
      "         1.0       0.73      0.76      0.74    156066\n",
      "\n",
      "    accuracy                           0.74    312132\n",
      "   macro avg       0.74      0.74      0.74    312132\n",
      "weighted avg       0.74      0.74      0.74    312132\n",
      "\n",
      "Random Oversampling on the test data produced the following:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.72      0.82     52090\n",
      "         1.0       0.34      0.75      0.46      9653\n",
      "\n",
      "    accuracy                           0.73     61743\n",
      "   macro avg       0.64      0.74      0.64     61743\n",
      "weighted avg       0.85      0.73      0.76     61743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#binary train and test accuracy (oversampled pca)\n",
    "print(\"Random Oversampling logistic regression model produced the following:\\n\" + classification_report(y_oversampled_binary, lr_ros_pca_binary.predict(X_pca_oversampled_binary_scaled)))\n",
    "print(\"Random Oversampling on the test data produced the following:\\n\" + classification_report(y_test_binary, lr_ros_pca_binary.predict(X_pca_test_binary_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Undersampling logistic regression model produced the following:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.73      0.74     29163\n",
      "         1.0       0.73      0.76      0.75     29163\n",
      "\n",
      "    accuracy                           0.74     58326\n",
      "   macro avg       0.74      0.74      0.74     58326\n",
      "weighted avg       0.74      0.74      0.74     58326\n",
      "\n",
      "Random undersampling on the test data produced the following:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.72      0.82     52090\n",
      "         1.0       0.34      0.76      0.46      9653\n",
      "\n",
      "    accuracy                           0.73     61743\n",
      "   macro avg       0.64      0.74      0.64     61743\n",
      "weighted avg       0.85      0.73      0.76     61743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#binary train and test accuracy (undersampled pca)\n",
    "print(\"Random Undersampling logistic regression model produced the following:\\n\" + classification_report(y_undersampled_binary, lr_rus_pca_binary.predict(X_pca_undersampled_binary_scaled)))\n",
    "print(\"Random undersampling on the test data produced the following:\\n\" + classification_report(y_test_binary, lr_rus_pca_binary.predict(X_pca_test_binary_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic Model setup for trying different models\n",
    "* SVC: sucked, didn't work, took too long to train >15 hours - possible to train it on a GPU, maybe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " BINARY DATA \n",
      "\n",
      "Undersample, binary, training data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.74      0.76     29163\n",
      "         1.0       0.75      0.81      0.78     29163\n",
      "\n",
      "    accuracy                           0.77     58326\n",
      "   macro avg       0.77      0.77      0.77     58326\n",
      "weighted avg       0.77      0.77      0.77     58326\n",
      "\n",
      "Undersample, binary, testing data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.71      0.81     52090\n",
      "         1.0       0.34      0.79      0.47      9653\n",
      "\n",
      "    accuracy                           0.72     61743\n",
      "   macro avg       0.64      0.75      0.64     61743\n",
      "weighted avg       0.85      0.72      0.76     61743\n",
      "\n",
      "Oversample, binary, training data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.73      0.76    156066\n",
      "         1.0       0.75      0.80      0.77    156066\n",
      "\n",
      "    accuracy                           0.77    312132\n",
      "   macro avg       0.77      0.77      0.77    312132\n",
      "weighted avg       0.77      0.77      0.77    312132\n",
      "\n",
      "Oversample, binary, test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.72      0.82     52090\n",
      "         1.0       0.34      0.77      0.47      9653\n",
      "\n",
      "    accuracy                           0.73     61743\n",
      "   macro avg       0.64      0.75      0.65     61743\n",
      "weighted avg       0.85      0.73      0.77     61743\n",
      "\n",
      "BINARY PCA DATA\n",
      "Undersample, binary, training data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.72      0.77     29163\n",
      "         1.0       0.75      0.84      0.80     29163\n",
      "\n",
      "    accuracy                           0.78     58326\n",
      "   macro avg       0.79      0.78      0.78     58326\n",
      "weighted avg       0.79      0.78      0.78     58326\n",
      "\n",
      "Undersample, binary, testing data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.67      0.79     52090\n",
      "         1.0       0.31      0.81      0.45      9653\n",
      "\n",
      "    accuracy                           0.69     61743\n",
      "   macro avg       0.63      0.74      0.62     61743\n",
      "weighted avg       0.85      0.69      0.73     61743\n",
      "\n",
      "Oversample, binary, pca, training data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.70      0.76    156066\n",
      "         1.0       0.74      0.85      0.79    156066\n",
      "\n",
      "    accuracy                           0.77    312132\n",
      "   macro avg       0.78      0.77      0.77    312132\n",
      "weighted avg       0.78      0.77      0.77    312132\n",
      "\n",
      "Oversample, binary, pca, test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.69      0.80     52090\n",
      "         1.0       0.32      0.79      0.46      9653\n",
      "\n",
      "    accuracy                           0.71     61743\n",
      "   macro avg       0.63      0.74      0.63     61743\n",
      "weighted avg       0.85      0.71      0.75     61743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model_oversampled = RandomForestClassifier().fit(X_oversampled_multiclass, y_oversampled_multiclass)\n",
    "# model_undersampled = RandomForestClassifier().fit(X_undersampled_multiclass, y_undersampled_multiclass)\n",
    "model_oversampled_binary = RandomForestClassifier(max_depth=10).fit(X_oversampled_binary, y_oversampled_binary)\n",
    "model_undersampled_binary = RandomForestClassifier(max_depth=10).fit(X_undersampled_binary, y_undersampled_binary)\n",
    "\n",
    "# model_oversampled_pca = RandomForestClassifier().fit(X_pca_oversampled_multiclass_scaled, y_oversampled_multiclass)\n",
    "# model_undersampled_pca = RandomForestClassifier().fit(X_pca_undersampled_multiclass_scaled, y_undersampled_multiclass)\n",
    "model_oversampled_binary_pca = RandomForestClassifier(max_depth=10).fit(X_pca_oversampled_binary_scaled, y_oversampled_binary)\n",
    "model_undersampled_binary_pca = RandomForestClassifier(max_depth=10).fit(X_pca_undersampled_binary_scaled, y_undersampled_binary)    \n",
    "\n",
    "# print(\"\\n MULTICLASS DATA \\n\")\n",
    "# print(\"Undersample, multiclass, training data report:\\n\" + classification_report(y_undersampled_multiclass, model_undersampled.predict(X_undersampled_multiclass)))\n",
    "# print(\"Undersample, multiclass, test data report:\\n\" + classification_report(y_test_multiclass, model_undersampled.predict(X_test_multiclass)))\n",
    "# print(\"Oversample, multiclass, training data:\\n\" + classification_report(y_oversampled_multiclass, model_oversampled.predict(X_oversampled_multiclass)))\n",
    "# print(\"Oversample, multiclass, test data:\\n\" + classification_report(y_test_multiclass, model_oversampled.predict(X_test_multiclass)))\n",
    "\n",
    "print(\"\\n BINARY DATA \\n\")\n",
    "print(\"Undersample, binary, training data:\\n\" + classification_report(y_undersampled_binary, model_undersampled_binary.predict(X_undersampled_binary)))\n",
    "print(\"Undersample, binary, testing data:\\n\" + classification_report(y_test_binary, model_undersampled_binary.predict(X_test_binary)))\n",
    "print(\"Oversample, binary, training data:\\n\" + classification_report(y_oversampled_binary, model_oversampled_binary.predict(X_oversampled_binary)))\n",
    "print(\"Oversample, binary, test data:\\n\" + classification_report(y_test_binary, model_oversampled_binary.predict(X_test_binary)))\n",
    "\n",
    "# print('MULTICLASS PCA DATA')\n",
    "# print(\"Undersample, multiclass, training data report:\\n\" + classification_report(y_undersampled_multiclass, model_undersampled_pca.predict(X_pca_undersampled_multiclass_scaled)))\n",
    "# print(\"Undersample, multiclass, test data report:\\n\" + classification_report(y_test_multiclass, model_undersampled_pca.predict(X_pca_test_multiclass_scaled)))\n",
    "# print(\"Oversample, multiclass, training data:\\n\" + classification_report(y_oversampled_multiclass, model_oversampled_pca.predict(X_pca_oversampled_multiclass_scaled)))\n",
    "# print(\"Oversample, multiclass, test data:\\n\" + classification_report(y_test_multiclass, model_oversampled_pca.predict(X_pca_test_multiclass_scaled)))\n",
    "\n",
    "print('BINARY PCA DATA')\n",
    "print(\"Undersample, binary, training data:\\n\" + classification_report(y_undersampled_binary, model_undersampled_binary_pca.predict(X_pca_undersampled_binary_scaled)))\n",
    "print(\"Undersample, binary, testing data:\\n\" + classification_report(y_test_binary, model_undersampled_binary_pca.predict(X_pca_test_binary_scaled)))\n",
    "print(\"Oversample, binary, pca, training data:\\n\" + classification_report(y_oversampled_binary, model_oversampled_binary_pca.predict(X_pca_oversampled_binary_scaled)))\n",
    "print(\"Oversample, binary, pca, test data:\\n\" + classification_report(y_test_binary, model_oversampled_binary_pca.predict(X_pca_test_binary_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Select Preferred Models & Optimize\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [10, 50, 100, 200], \n",
    "    'max_depth': [10, 15, 20, 30], \n",
    "    'min_samples_split': [2, 4, 6], \n",
    "    'min_samples_leaf': [1, 2, 4] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cv = RandomForestClassifier(random_state=0)\n",
    "grid_search = GridSearchCV(model_cv, param_grid_rf, cv=5, n_jobs=-1, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_oversampled_binary, y_oversampled_binary)\n",
      "File \u001b[1;32mc:\\Users\\matt.dipinto\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\matt.dipinto\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\matt.dipinto\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\matt.dipinto\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\matt.dipinto\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\matt.dipinto\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\matt.dipinto\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\matt.dipinto\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matt.dipinto\\AppData\\Local\\anaconda3\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\matt.dipinto\\AppData\\Local\\anaconda3\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_oversampled_binary, y_oversampled_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 30,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_RF = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversample, binary, testing data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.92      0.90     52090\n",
      "         1.0       0.46      0.36      0.40      9653\n",
      "\n",
      "    accuracy                           0.83     61743\n",
      "   macro avg       0.67      0.64      0.65     61743\n",
      "weighted avg       0.82      0.83      0.82     61743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report for the best model\n",
    "print(\"Oversample, binary, testing data:\\n\" + classification_report(y_test_binary, best_RF.predict(X_test_binary)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lr = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Inverse of regularization strength\n",
    "    'penalty': ['l1', 'l2'],  # Type of regularization\n",
    "    'solver': ['liblinear', 'saga']  # Algorithms that support both l1 and l2 penalties\n",
    "}\n",
    "model_cv_lr = LogisticRegression(random_state=0)\n",
    "grid_search_lr = GridSearchCV(model_cv_lr, param_grid_lr, cv=5, n_jobs=-1, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(random_state=0), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;saga&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(random_state=0), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;saga&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(random_state=0), n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['liblinear', 'saga']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_lr.fit(X_oversampled_binary, y_oversampled_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_LR = grid_search_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversample, binary, testing data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.73      0.82     52090\n",
      "         1.0       0.34      0.77      0.47      9653\n",
      "\n",
      "    accuracy                           0.73     61743\n",
      "   macro avg       0.64      0.75      0.65     61743\n",
      "weighted avg       0.85      0.73      0.77     61743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Oversample, binary, testing data:\\n\" + classification_report(y_test_binary, best_LR.predict(X_test_binary)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingClassifier(random_state=0),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.2], &#x27;max_depth&#x27;: [5, 20],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 4],\n",
       "                         &#x27;n_estimators&#x27;: [100, 300], &#x27;subsample&#x27;: [0.8, 1.0]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingClassifier(random_state=0),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.2], &#x27;max_depth&#x27;: [5, 20],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 4],\n",
       "                         &#x27;n_estimators&#x27;: [100, 300], &#x27;subsample&#x27;: [0.8, 1.0]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingClassifier(random_state=0),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.2], 'max_depth': [5, 20],\n",
       "                         'max_features': ['sqrt', 'log2', None],\n",
       "                         'min_samples_leaf': [1, 2],\n",
       "                         'min_samples_split': [2, 4],\n",
       "                         'n_estimators': [100, 300], 'subsample': [0.8, 1.0]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train a gradientboostingclassifier on the undersampled binary data\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "param_grid_gbc = {\n",
    "    'n_estimators': [100, 300],\n",
    "    'learning_rate': [0.01, 0.2],\n",
    "    'max_depth': [5, 20],\n",
    "    'min_samples_split': [2, 4],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_cv_gbc = GradientBoostingClassifier(random_state=0)\n",
    "grid_search_gbc = GridSearchCV(model_cv_gbc, param_grid_gbc, cv=5, n_jobs=-1, verbose=3)\n",
    "\n",
    "grid_search_gbc.fit(X_undersampled_binary, y_undersampled_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.2,\n",
       " 'max_depth': 5,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100,\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_gbc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_GBC = grid_search_gbc.best_estimator_\n",
    "print(\"Undersample, binary, testing data:\\n\" + classification_report(y_test_binary, Best_GBC.predict(X_test_binary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.85;, score=0.774 total time=   0.6s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.85;, score=0.777 total time=   0.6s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.85;, score=0.784 total time=   0.4s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.9;, score=0.775 total time=   0.4s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.9;, score=0.776 total time=   0.4s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.9;, score=0.784 total time=   0.4s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.95;, score=0.776 total time=   0.4s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.95;, score=0.775 total time=   0.5s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.95;, score=0.784 total time=   0.5s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.85;, score=0.779 total time=   0.9s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.85;, score=0.786 total time=   1.2s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.85;, score=0.792 total time=   0.9s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=0.780 total time=   0.9s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=0.785 total time=   0.9s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=0.789 total time=   0.9s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.95;, score=0.781 total time=   0.9s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.95;, score=0.786 total time=   1.0s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.95;, score=0.790 total time=   1.0s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.85;, score=0.782 total time=   1.4s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.85;, score=0.788 total time=   1.4s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.85;, score=0.792 total time=   1.4s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.9;, score=0.783 total time=   1.3s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.9;, score=0.787 total time=   1.5s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.9;, score=0.791 total time=   1.7s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.95;, score=0.784 total time=   1.4s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.95;, score=0.790 total time=   1.5s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.95;, score=0.791 total time=   1.4s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.85;, score=0.775 total time=   0.4s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.85;, score=0.777 total time=   0.4s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.85;, score=0.784 total time=   0.4s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.9;, score=0.776 total time=   0.4s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.9;, score=0.776 total time=   0.4s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.9;, score=0.784 total time=   0.4s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.95;, score=0.776 total time=   0.5s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.95;, score=0.776 total time=   0.5s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.95;, score=0.784 total time=   0.5s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.85;, score=0.780 total time=   1.2s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.85;, score=0.786 total time=   1.0s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.85;, score=0.791 total time=   1.2s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.9;, score=0.781 total time=   1.0s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.9;, score=0.785 total time=   1.0s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.9;, score=0.789 total time=   1.0s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.95;, score=0.780 total time=   1.0s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.95;, score=0.787 total time=   0.9s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.95;, score=0.790 total time=   0.9s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.85;, score=0.783 total time=   1.4s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.85;, score=0.787 total time=   1.4s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.85;, score=0.791 total time=   1.4s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.9;, score=0.785 total time=   1.4s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.9;, score=0.787 total time=   1.4s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.9;, score=0.791 total time=   1.4s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.95;, score=0.784 total time=   1.4s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.95;, score=0.789 total time=   1.4s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.95;, score=0.790 total time=   1.4s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.85;, score=0.783 total time=   0.8s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.85;, score=0.784 total time=   0.7s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.85;, score=0.795 total time=   0.7s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.9;, score=0.788 total time=   0.8s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.9;, score=0.788 total time=   0.7s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.9;, score=0.793 total time=   0.7s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.95;, score=0.786 total time=   0.7s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.95;, score=0.787 total time=   0.8s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.95;, score=0.793 total time=   0.9s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.85;, score=0.788 total time=   1.7s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.85;, score=0.789 total time=   1.8s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.85;, score=0.793 total time=   1.8s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=0.789 total time=   1.5s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=0.792 total time=   1.7s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=0.794 total time=   1.4s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.95;, score=0.790 total time=   1.4s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.95;, score=0.791 total time=   1.5s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.95;, score=0.793 total time=   1.5s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.85;, score=0.789 total time=   2.4s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.85;, score=0.788 total time=   2.1s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.85;, score=0.793 total time=   2.1s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.9;, score=0.791 total time=   2.2s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.9;, score=0.794 total time=   2.1s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.9;, score=0.795 total time=   2.2s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.95;, score=0.790 total time=   2.3s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.95;, score=0.791 total time=   2.1s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.95;, score=0.794 total time=   2.1s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.85;, score=0.783 total time=   0.7s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.85;, score=0.787 total time=   0.6s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.85;, score=0.797 total time=   0.8s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.9;, score=0.789 total time=   0.9s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.9;, score=0.787 total time=   0.7s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.9;, score=0.795 total time=   0.7s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.95;, score=0.787 total time=   0.7s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.95;, score=0.788 total time=   0.9s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.95;, score=0.795 total time=   0.8s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.85;, score=0.787 total time=   1.6s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.85;, score=0.789 total time=   1.3s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.85;, score=0.797 total time=   1.4s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.9;, score=0.791 total time=   1.5s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.9;, score=0.791 total time=   1.3s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.9;, score=0.796 total time=   1.6s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.95;, score=0.790 total time=   1.4s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.95;, score=0.793 total time=   1.4s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.95;, score=0.794 total time=   1.7s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.85;, score=0.788 total time=   2.0s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.85;, score=0.789 total time=   2.0s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.85;, score=0.794 total time=   2.0s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.9;, score=0.789 total time=   2.0s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.9;, score=0.789 total time=   2.2s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.9;, score=0.794 total time=   2.0s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.95;, score=0.791 total time=   2.1s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.95;, score=0.792 total time=   2.2s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.95;, score=0.793 total time=   2.1s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.85;, score=0.776 total time=   0.4s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.85;, score=0.783 total time=   0.4s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.85;, score=0.789 total time=   0.4s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.9;, score=0.781 total time=   0.4s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.9;, score=0.783 total time=   0.4s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.9;, score=0.787 total time=   0.4s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.95;, score=0.784 total time=   0.4s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.95;, score=0.782 total time=   0.4s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.95;, score=0.788 total time=   0.4s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.85;, score=0.781 total time=   0.9s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.85;, score=0.786 total time=   0.9s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.85;, score=0.789 total time=   0.9s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=0.783 total time=   0.9s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=0.784 total time=   1.0s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=0.788 total time=   1.0s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.95;, score=0.785 total time=   0.9s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.95;, score=0.785 total time=   1.0s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.95;, score=0.791 total time=   1.0s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.85;, score=0.783 total time=   1.3s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.85;, score=0.788 total time=   1.3s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.85;, score=0.790 total time=   1.3s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.9;, score=0.784 total time=   1.3s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.9;, score=0.788 total time=   1.3s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.9;, score=0.790 total time=   1.3s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.95;, score=0.784 total time=   1.4s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.95;, score=0.787 total time=   1.3s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.95;, score=0.791 total time=   1.3s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.85;, score=0.778 total time=   0.4s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.85;, score=0.783 total time=   0.4s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.85;, score=0.789 total time=   0.4s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.9;, score=0.779 total time=   0.4s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.9;, score=0.783 total time=   0.4s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.9;, score=0.788 total time=   0.4s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.95;, score=0.784 total time=   0.4s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.95;, score=0.781 total time=   0.4s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.95;, score=0.789 total time=   0.4s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.85;, score=0.782 total time=   0.9s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.85;, score=0.788 total time=   0.9s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.85;, score=0.789 total time=   0.9s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.9;, score=0.782 total time=   0.9s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.9;, score=0.784 total time=   0.9s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.9;, score=0.787 total time=   0.9s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.95;, score=0.784 total time=   0.9s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.95;, score=0.785 total time=   0.9s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.95;, score=0.790 total time=   0.9s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.85;, score=0.786 total time=   1.3s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.85;, score=0.789 total time=   1.3s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.85;, score=0.789 total time=   1.4s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.9;, score=0.784 total time=   1.3s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.9;, score=0.786 total time=   1.3s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.9;, score=0.788 total time=   1.3s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.95;, score=0.784 total time=   1.3s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.95;, score=0.787 total time=   1.4s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.95;, score=0.790 total time=   1.3s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.85;, score=0.789 total time=   0.6s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.85;, score=0.791 total time=   0.6s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.85;, score=0.793 total time=   0.7s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.9;, score=0.791 total time=   0.6s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.9;, score=0.788 total time=   0.6s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.9;, score=0.790 total time=   0.6s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.95;, score=0.786 total time=   0.6s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.95;, score=0.787 total time=   0.7s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50, subsample=0.95;, score=0.793 total time=   0.6s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.85;, score=0.790 total time=   1.3s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.85;, score=0.791 total time=   1.4s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.85;, score=0.791 total time=   1.3s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=0.790 total time=   1.3s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=0.790 total time=   1.3s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=0.792 total time=   1.3s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.95;, score=0.790 total time=   1.4s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.95;, score=0.785 total time=   1.4s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.95;, score=0.792 total time=   1.4s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.85;, score=0.788 total time=   2.0s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.85;, score=0.788 total time=   2.0s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.85;, score=0.787 total time=   2.0s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.9;, score=0.788 total time=   2.0s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.9;, score=0.786 total time=   2.0s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.9;, score=0.790 total time=   2.0s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.95;, score=0.787 total time=   2.1s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.95;, score=0.785 total time=   2.0s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150, subsample=0.95;, score=0.789 total time=   2.1s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.85;, score=0.788 total time=   0.7s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.85;, score=0.790 total time=   0.7s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.85;, score=0.792 total time=   0.6s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.9;, score=0.788 total time=   0.6s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.9;, score=0.789 total time=   0.6s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.9;, score=0.791 total time=   0.6s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.95;, score=0.788 total time=   0.7s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.95;, score=0.788 total time=   0.6s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50, subsample=0.95;, score=0.794 total time=   0.6s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.85;, score=0.789 total time=   1.3s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.85;, score=0.791 total time=   1.3s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.85;, score=0.792 total time=   1.3s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.9;, score=0.791 total time=   1.4s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.9;, score=0.788 total time=   1.3s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.9;, score=0.790 total time=   1.3s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.95;, score=0.791 total time=   1.3s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.95;, score=0.791 total time=   1.4s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100, subsample=0.95;, score=0.793 total time=   1.3s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.85;, score=0.789 total time=   2.0s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.85;, score=0.787 total time=   2.0s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.85;, score=0.791 total time=   2.1s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.9;, score=0.790 total time=   2.0s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.9;, score=0.789 total time=   2.0s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.9;, score=0.786 total time=   2.3s\n",
      "[CV 1/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.95;, score=0.790 total time=   2.1s\n",
      "[CV 2/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.95;, score=0.789 total time=   2.0s\n",
      "[CV 3/3] END learning_rate=0.2, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150, subsample=0.95;, score=0.790 total time=   2.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=GradientBoostingClassifier(random_state=0),\n",
       "             n_jobs=1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.1, 0.2], &#x27;max_depth&#x27;: [3, 5],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;], &#x27;min_samples_leaf&#x27;: [2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 150],\n",
       "                         &#x27;subsample&#x27;: [0.85, 0.9, 0.95]},\n",
       "             scoring=&#x27;recall&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=GradientBoostingClassifier(random_state=0),\n",
       "             n_jobs=1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.1, 0.2], &#x27;max_depth&#x27;: [3, 5],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;], &#x27;min_samples_leaf&#x27;: [2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 150],\n",
       "                         &#x27;subsample&#x27;: [0.85, 0.9, 0.95]},\n",
       "             scoring=&#x27;recall&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=GradientBoostingClassifier(random_state=0),\n",
       "             n_jobs=1,\n",
       "             param_grid={'learning_rate': [0.1, 0.2], 'max_depth': [3, 5],\n",
       "                         'max_features': ['sqrt'], 'min_samples_leaf': [2, 4],\n",
       "                         'min_samples_split': [2],\n",
       "                         'n_estimators': [50, 100, 150],\n",
       "                         'subsample': [0.85, 0.9, 0.95]},\n",
       "             scoring='recall', verbose=3)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_gbc_2 = {'learning_rate': [0.1, 0.2],\n",
    " 'max_depth': [3, 5],\n",
    " 'max_features': ['sqrt'],\n",
    " 'min_samples_leaf': [2, 4],\n",
    " 'min_samples_split': [2],\n",
    " 'n_estimators': [50, 100, 150],\n",
    " 'subsample': [0.85, 0.9, 0.95]}\n",
    "\n",
    "model_cv_gbc_2 = GradientBoostingClassifier(random_state=0)\n",
    "grid_search_gbc_2 = GridSearchCV(model_cv_gbc_2, param_grid_gbc_2, cv=3, n_jobs=1, verbose=3, scoring='recall')\n",
    "grid_search_gbc_2.fit(X_undersampled_binary, y_undersampled_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.2,\n",
       " 'max_depth': 5,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100,\n",
       " 'subsample': 0.9}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_gbc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersample, binary, testing data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.71      0.81     52090\n",
      "         1.0       0.34      0.79      0.47      9653\n",
      "\n",
      "    accuracy                           0.73     61743\n",
      "   macro avg       0.64      0.75      0.64     61743\n",
      "weighted avg       0.85      0.73      0.76     61743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Best_GBC_2 = grid_search_gbc.best_estimator_\n",
    "print(\"Undersample, binary, testing data:\\n\" + classification_report(y_test_binary, Best_GBC.predict(X_test_binary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GBC - Undersample, binary, testing data:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.71      0.81     52090\n",
      "         1.0       0.34      0.79      0.47      9653\n",
      "\n",
      "    accuracy                           0.73     61743\n",
      "   macro avg       0.64      0.75      0.64     61743\n",
      "weighted avg       0.85      0.73      0.76     61743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Best_GBC_2 = grid_search_gbc.best_estimator_\n",
    "print(\"\\nGBC - Undersample, binary, testing data:\\n\\n\" + classification_report(y_test_binary, Best_GBC.predict(X_test_binary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
